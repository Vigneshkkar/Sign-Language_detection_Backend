{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'Dataset')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client.Dataset\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = db.PoseValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(poses.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>word</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620bc2440d16b90ca807d48b</td>\n",
       "      <td>hi</td>\n",
       "      <td>[{'faceLandmarks': [{'x': 0.5134519338607788, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>620bc2440d16b90ca807d48c</td>\n",
       "      <td>hi</td>\n",
       "      <td>[{'faceLandmarks': [{'x': 0.5285636186599731, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>620bc2440d16b90ca807d48d</td>\n",
       "      <td>hi</td>\n",
       "      <td>[{'faceLandmarks': [{'x': 0.5248129963874817, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>620bc28a0d16b90ca807d48f</td>\n",
       "      <td>hi</td>\n",
       "      <td>[{'faceLandmarks': [{'x': 0.5378047823905945, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>620bc28a0d16b90ca807d490</td>\n",
       "      <td>hi</td>\n",
       "      <td>[{'faceLandmarks': [{'x': 0.5376523733139038, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id word  \\\n",
       "0  620bc2440d16b90ca807d48b   hi   \n",
       "1  620bc2440d16b90ca807d48c   hi   \n",
       "2  620bc2440d16b90ca807d48d   hi   \n",
       "3  620bc28a0d16b90ca807d48f   hi   \n",
       "4  620bc28a0d16b90ca807d490   hi   \n",
       "\n",
       "                                                data  \n",
       "0  [{'faceLandmarks': [{'x': 0.5134519338607788, ...  \n",
       "1  [{'faceLandmarks': [{'x': 0.5285636186599731, ...  \n",
       "2  [{'faceLandmarks': [{'x': 0.5248129963874817, ...  \n",
       "3  [{'faceLandmarks': [{'x': 0.5378047823905945, ...  \n",
       "4  [{'faceLandmarks': [{'x': 0.5376523733139038, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['data'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(result):\n",
    "    pose = np.array([[res['x'], res['y'], res['z'], res['visibility']] for res in result[\"poseLandmarks\"]]).flatten() if \"poseLandmarks\" in result else np.zeros(33*4)\n",
    "    lh = np.array([[res['x'], res['y'], res['z']] for res in result[\"leftHandLandmarks\"]]).flatten() if \"leftHandLandmarks\" in result else np.zeros(21*3)\n",
    "    rh = np.array([[res['x'], res['y'], res['z']] for res in result[\"rightHandLandmarks\"]]).flatten() if \"rightHandLandmarks\" in result else np.zeros(21*3)\n",
    "    face = np.array([[res['x'], res['y'], res['z']] for res in result[\"faceLandmarks\"]]).flatten() if \"faceLandmarks\" in result else np.zeros(468*3)\n",
    "    # ea = np.array([[res['x'], res['y'], res['z']] for res in result[\"ea\"]]).flatten() if \"ea\" in result else np.zeros(33*3)\n",
    "    return np.concatenate([pose, lh, rh, face])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keypoints(df['data'][0][20]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for videos in df['data']:\n",
    "    frame_data = []\n",
    "    for frames in videos:\n",
    "        frame_data.append(extract_keypoints(frames))\n",
    "    data.append(frame_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 40, 1662)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = np.array(df['word']).flatten()\n",
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': 0, 'i': 1, 'name': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label:num for num, label in enumerate(np.unique(words))}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label_map[word] for word in df['word']]\n",
    "df['word'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/GPU'):\n",
    "#     a = tf.random.normal(shape=(2,), dtype=tf.float32)\n",
    "#     b = tf.nn.relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/CPU'):\n",
    "# model = Sequential()\n",
    "# model.add(Bidirectional(LSTM(64,dropout=0.2, recurrent_dropout=0.2, return_sequences=True, activation='relu', input_shape=(40, 1761))))\n",
    "# model.add(Bidirectional(LSTM(128, return_sequences=True, activation='relu')))\n",
    "# model.add(Bidirectional(LSTM(64, return_sequences=True, activation='relu')))\n",
    "# model.add(Bidirectional(LSTM(128,dropout=0.2, recurrent_dropout=0.2, return_sequences=True, activation='relu')))\n",
    "# # model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "# # model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(Bidirectional(LSTM(64, return_sequences=False, activation='relu')))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "# model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(TimeDistributed(Conv2D(1, (2,2), activation='relu', padding='same', input_shape=(40,1662,1))))\n",
    "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "# model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(100, input_shape=(40, 1662)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# model.add(LSTM(64,return_sequences=True, activation='relu', input_shape=(40, 1662)))\n",
    "# model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "# model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 40, 1662)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 2s 61ms/step - loss: 1.1491 - categorical_accuracy: 0.3509\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.0744 - categorical_accuracy: 0.3947\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.0764 - categorical_accuracy: 0.4035\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.0298 - categorical_accuracy: 0.4211\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 1.0397 - categorical_accuracy: 0.4561\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.9932 - categorical_accuracy: 0.5088\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.9221 - categorical_accuracy: 0.5263\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.8853 - categorical_accuracy: 0.5702\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.8586 - categorical_accuracy: 0.6228\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.7556 - categorical_accuracy: 0.6930\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.7102 - categorical_accuracy: 0.7895\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.6567 - categorical_accuracy: 0.7807\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.6587 - categorical_accuracy: 0.7544\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.7048 - categorical_accuracy: 0.7018\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.6447 - categorical_accuracy: 0.7982\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.5569 - categorical_accuracy: 0.8070\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.5121 - categorical_accuracy: 0.8333\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.5133 - categorical_accuracy: 0.8421\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.5683 - categorical_accuracy: 0.7632\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.6392 - categorical_accuracy: 0.7281\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.6447 - categorical_accuracy: 0.7281\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.4417 - categorical_accuracy: 0.8333\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.4646 - categorical_accuracy: 0.8333\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4162 - categorical_accuracy: 0.8772\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.4016 - categorical_accuracy: 0.8596\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.2979 - categorical_accuracy: 0.9298\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.3832 - categorical_accuracy: 0.8421\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.3814 - categorical_accuracy: 0.8333\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.3728 - categorical_accuracy: 0.8596\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.4179 - categorical_accuracy: 0.8509\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.3571 - categorical_accuracy: 0.8772\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.3424 - categorical_accuracy: 0.8684\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.3038 - categorical_accuracy: 0.8860\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.2858 - categorical_accuracy: 0.9123\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.2637 - categorical_accuracy: 0.9123\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.3445 - categorical_accuracy: 0.8772\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.2298 - categorical_accuracy: 0.9211\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.2924 - categorical_accuracy: 0.8772\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.3004 - categorical_accuracy: 0.8860\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.3044 - categorical_accuracy: 0.8772\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.2601 - categorical_accuracy: 0.9211\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.3198 - categorical_accuracy: 0.8860\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.2068 - categorical_accuracy: 0.9386\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.1782 - categorical_accuracy: 0.9737\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.2127 - categorical_accuracy: 0.9386\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.1662 - categorical_accuracy: 0.9474\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.1726 - categorical_accuracy: 0.9211\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.2100 - categorical_accuracy: 0.9386\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.2222 - categorical_accuracy: 0.9123\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.2172 - categorical_accuracy: 0.9298\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.2047 - categorical_accuracy: 0.9298\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.1461 - categorical_accuracy: 0.9474\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1393 - categorical_accuracy: 0.9737\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.1793 - categorical_accuracy: 0.9561\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1369 - categorical_accuracy: 0.9474\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.1848 - categorical_accuracy: 0.9211\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.1534 - categorical_accuracy: 0.9649\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.1444 - categorical_accuracy: 0.9561\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.1163 - categorical_accuracy: 0.9561\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0929 - categorical_accuracy: 0.9825\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1279 - categorical_accuracy: 0.9737\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0906 - categorical_accuracy: 0.9737\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0736 - categorical_accuracy: 0.9737\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.1134 - categorical_accuracy: 0.9561\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0962 - categorical_accuracy: 0.9386\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1137 - categorical_accuracy: 0.9474\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0861 - categorical_accuracy: 0.9737\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0613 - categorical_accuracy: 0.9912\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1034 - categorical_accuracy: 0.9649\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0539 - categorical_accuracy: 0.9912\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0598 - categorical_accuracy: 0.9737\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0568 - categorical_accuracy: 0.9912\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0479 - categorical_accuracy: 0.9912\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0728 - categorical_accuracy: 0.9649\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0429 - categorical_accuracy: 0.9912\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.0560 - categorical_accuracy: 0.9825\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0254 - categorical_accuracy: 1.0000\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0490 - categorical_accuracy: 0.9825\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0491 - categorical_accuracy: 0.9825\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0365 - categorical_accuracy: 0.9912\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0234 - categorical_accuracy: 1.0000\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.0397 - categorical_accuracy: 0.9737\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0290 - categorical_accuracy: 0.9912\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0257 - categorical_accuracy: 0.9912\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0209 - categorical_accuracy: 1.0000\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0177 - categorical_accuracy: 1.0000\n",
      "Epoch 87/2000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.0629 - categorical_accuracy: 0.9896"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vigneshkkar/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/model.ipynb Cell 25'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vigneshkkar/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/model.ipynb#ch0000024?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[tb_callback])\n",
      "File \u001b[0;32m~/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Documents/Vigneshkkar/AIML/AI ML Lab/Sign Language Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///~/Documents/Vigneshkkar/AIML/AI%20ML%20Lab/Sign%20Language%20Detection/back-end/.SLR_BE/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 100)               705200    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 715,603\n",
      "Trainable params: 715,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "np.argmax(res[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 363ms/step - loss: 3.7332e-04 - categorical_accuracy: 1.0000\n",
      "Test set\n",
      "  Loss: 0.000\n",
      "  Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 0],\n",
       "        [0, 2]],\n",
       "\n",
       "       [[2, 0],\n",
       "        [0, 4]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('SLD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('SLD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 100)               705200    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 715,603\n",
      "Trainable params: 715,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j5/v6fyg4pd095c4c97hw6gzbdr0000gn/T/tmpxn9gkmrh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/j5/v6fyg4pd095c4c97hw6gzbdr0000gn/T/tmpxn9gkmrh/assets\n",
      "2022-02-15 15:14:41.845365: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-02-15 15:14:41.845383: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "2022-02-15 15:14:41.845490: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/j5/v6fyg4pd095c4c97hw6gzbdr0000gn/T/tmpxn9gkmrh\n",
      "2022-02-15 15:14:41.854530: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-02-15 15:14:41.854549: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/j5/v6fyg4pd095c4c97hw6gzbdr0000gn/T/tmpxn9gkmrh\n",
      "2022-02-15 15:14:41.899139: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-02-15 15:14:41.999773: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/j5/v6fyg4pd095c4c97hw6gzbdr0000gn/T/tmpxn9gkmrh\n",
      "2022-02-15 15:14:42.060955: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 215466 microseconds.\n",
      "2022-02-15 15:14:42.308577: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1892] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListFromTensor, FlexTensorListGetItem, FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListFromTensor(tensor<40x?x1662xf32>, tensor<2xi32>) -> (tensor<!tf_type.variant<tensor<?x1662xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListGetItem(tensor<!tf_type.variant<tensor<?x1662xf32>>>, tensor<i32>, tensor<2xi32>) -> (tensor<?x1662xf32>) : {device = \"\"}\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x100xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x100xf32>>>, tensor<i32>, tensor<?x100xf32>) -> (tensor<!tf_type.variant<tensor<?x100xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x100xf32>>>, tensor<2xi32>) -> (tensor<?x?x100xf32>) : {device = \"\", num_elements = -1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
      "2022-02-15 15:14:42.310696: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor sequential_4/dense_12/MatMul because it has fewer than 1024 elements (300).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "729968"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
    "# tflite_model = converter.convert()\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.experimental_new_converter=True\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "tfmodel = converter.convert()\n",
    "open('image_model.tflite', 'wb').write(tfmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(loaded_model, \"./jsModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "997d5eec0cf075e47f999f62fb411c0faccc1853671279a6518a3b2dcc03ec85"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.SLR_BE': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
